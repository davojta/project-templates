# 2025 Geospatial OSM Processing Stack for Python CLI/Notebooks

## Executive Summary

This is a production-ready, modern stack for processing OpenStreetMap data with geospatial analysis at scale. Built on **SedonaDB** (single-node spatial analytics), **QuackOSM** (efficient OSM ingestion), and **GeoParquet** (cloud-friendly storage).

**Why This Stack:**
- SedonaDB: 5-40x faster spatial operations than DuckDB/GeoPandas
- QuackOSM: Native caching, multithreaded OSMâ†’GeoParquet conversion
- GeoParquet: S3-compatible, columnar, preserves geometry
- Modern Python tooling: UV (fast package management), Click, plugin architecture
- Proven in 2025 benchmarks (SpatialBench)

---

## Part 1: Package Dependencies

### Core Geospatial

```toml
[project]
name = "osm-geo-processor"
version = "0.1.0"
description = "Geospatial OSM processing with SedonaDB and QuackOSM"
requires-python = ">=3.11"
dependencies = [
    # Core CLI framework
    "click>=8.1.0",
    "pydantic>=2.0.0",
    "rich>=13.7.0",

    # Primary spatial engine - CHOOSE ONE:
    "sedonadb>=1.8.0",  # â† RECOMMENDED: Fastest spatial operations

    # OSM data fetching
    "quackosm>=0.2.0",  # Caching, multithreaded, GeoParquet output

    # Spatial data operations & interoperability
    "geopandas>=1.0.0",  # For shapefile/GeoJSON read, dataframe ops
    "pyogrio>=0.10.0",  # Fast GDAL bindings (required by geopandas)
    "shapely>=2.0.0",  # Geometry operations

    # Data format handling
    "pyarrow>=16.0.0",  # Efficient Arrow/Parquet support
    "pandas>=2.0.0",  # Data manipulation
]

# Optional dependencies for specific features
[project.optional-dependencies]
performance = [
    "polars>=1.0.0",  # Faster dataframes
    "diskcache>=5.6.0",  # Advanced caching
]
viz = [
    "keplergl>=0.3.0",  # Web-based geospatial visualization
    "matplotlib>=3.8.0",  # Static plots
]
notebooks = [
    "jupyter>=1.0.0",
    "jupyterlab>=4.1.0",
    "ipywidgets>=8.1.0",
]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "pytest-cov>=5.0.0",
    "pytest-mock>=3.10.0",
    "ruff>=0.4.0",
    "pyright>=1.1.0",
]

[project.scripts]
osm-geo-cli = "osm_geo_processor.cli:main"

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",  # pycodestyle
    "F",  # Pyflakes
    "UP",  # pyupgrade
    "B",  # flake8-bugbear
    "SIM",  # flake8-simplify
    "I",  # isort
]
ignore = [
    "E501",  # line too long
    "B008",  # do not perform function calls in argument defaults
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"

[tool.pyright]
include = ["src"]
typeCheckingMode = "strict"

[tool.pytest.ini_options]
testpaths = ["tests"]
asyncio_mode = "auto"
addopts = "-ra -q --strict-markers"
```

### Visualization (Optional Dependencies)

Add these when needed:
```bash
uv add --optional keplergl matplotlib
```

### Development Tools

```bash
uv add --dev pytest pytest-asyncio pytest-cov pytest-mock ruff pyright
```

---

## Part 2: Project File Organization

### Modern Python Project Structure

```
osm-geo-processor/
â”œâ”€â”€ pyproject.toml                 # All configuration, dependencies
â”œâ”€â”€ uv.lock                        # Locked versions (auto-generated)
â”œâ”€â”€ README.md                      # Project documentation
â”œâ”€â”€ LICENSE                        # MIT or your choice
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env.example                   # Environment variables template
â”‚
â”œâ”€â”€ src/osm_geo_processor/         # Main package (src layout)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py                # Entry point for `python -m osm_geo_processor`
â”‚   â”‚
â”‚   â”œâ”€â”€ cli/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                # Main CLI app (Click app)
â”‚   â”‚   â”œâ”€â”€ download.py            # Download commands
â”‚   â”‚   â”œâ”€â”€ process.py             # Processing commands
â”‚   â”‚   â””â”€â”€ visualize.py           # Visualization commands
â”‚   â”‚
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ downloader.py          # QuackOSM wrapper
â”‚   â”‚   â”œâ”€â”€ processor.py           # SedonaDB operations
â”‚   â”‚   â”œâ”€â”€ spatial_ops.py         # Spatial analysis functions
â”‚   â”‚   â””â”€â”€ wikidata.py            # Wikidata integration
â”‚   â”‚
â”‚   â”œâ”€â”€ viz/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ kepler_maps.py         # Kepler.GL visualizations
â”‚   â”‚   â””â”€â”€ plots.py               # matplotlib/static visualizations
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ config.py              # Pydantic config models
â”‚   â”‚   â””â”€â”€ schemas.py             # Data schemas
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ cache.py               # Caching utilities
â”‚       â”œâ”€â”€ logging.py             # Logging setup
â”‚       â””â”€â”€ validation.py          # Input validation
â”‚
â”œâ”€â”€ data/                          # Local data directory
â”‚   â”œâ”€â”€ raw/                       # Raw OSM .pbf files
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â”œâ”€â”€ processed/                 # GeoParquet files
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ cache/                     # QuackOSM cache
â”‚       â””â”€â”€ .gitkeep
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                # pytest configuration
â”‚   â”œâ”€â”€ test_cli.py
â”‚   â”œâ”€â”€ test_downloader.py
â”‚   â”œâ”€â”€ test_processor.py
â”‚   â”œâ”€â”€ test_spatial_ops.py
â”‚   â”œâ”€â”€ test_wikidata.py
â”‚   â””â”€â”€ fixtures/
â”‚       â””â”€â”€ sample_data/           # Small test data
â”‚
â”œâ”€â”€ notebooks/                     # Development notebooks
â”‚   â”œâ”€â”€ .ipynb_checkpoints/
â”‚   â”œâ”€â”€ exploration.ipynb
â”‚   â””â”€â”€ benchmarking.ipynb
â”‚
â””â”€â”€ scripts/                       # Utility scripts (not importable)
    â”œâ”€â”€ download_test_data.sh
    â””â”€â”€ cleanup.sh
```

### Why This Structure

1. **Modular design:** Commands separated into logical modules
2. **Separation of concerns:** Core logic separate from CLI and visualization
3. **Source layout:** `src/` layout prevents import issues and better packaging
4. **Configuration:** All in `pyproject.toml` using standard Python packaging
5. **Scalable:** Easy to add new commands and functionality

---

## Part 3: Core Module Examples

### 1. CLI Entry Point (`src/osm_geo_processor/cli/main.py`)

```python
import click
from rich.console import Console
from . import download, process, visualize

console = Console()
app = click.Group(help="Geospatial OSM processing CLI")

# Add command groups
app.add_command(download.app, name="download")
app.add_command(process.app, name="process")
app.add_command(visualize.app, name="viz")

@app.command()
def version():
    """Show version information."""
    click.echo("osm-geo-processor version 0.1.0")

def main():
    """Main entry point for the CLI application."""
    app()

if __name__ == "__main__":
    main()
```

### 2. OSM Downloader (`osm_geo_processor/core/downloader.py`)

```python
from pathlib import Path
from quackosm import QuackOSM
import logging

logger = logging.getLogger(__name__)

class OSMDownloader:
    def __init__(self, cache_dir: Path = Path("data/cache")):
        self.cache_dir = cache_dir
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.downloader = QuackOSM()
    
    def download_region(
        self,
        bbox: tuple[float, float, float, float],
        tags: dict | None = None,
        output_path: Path | None = None
    ) -> Path:
        """
        Download OSM data for region.
        
        Args:
            bbox: (min_lon, min_lat, max_lon, max_lat)
            tags: OSM tags filter (e.g., {"building": ["residential"]})
            output_path: GeoParquet output location
        
        Returns:
            Path to GeoParquet file
        """
        if output_path is None:
            output_path = self.cache_dir / f"osm_{bbox[0]}_{bbox[1]}.geoparquet"
        
        logger.info(f"Downloading OSM data for bbox: {bbox}")
        
        # QuackOSM handles caching automatically
        self.downloader.download(
            bbox=bbox,
            tags=tags,
            output_path=str(output_path),
            file_format="geoparquet"
        )
        
        logger.info(f"Saved to {output_path}")
        return output_path
```

### 3. SedonaDB Processor (`osm_geo_processor/core/processor.py`)

```python
from pathlib import Path
import sedona.db
import logging

logger = logging.getLogger(__name__)

class SedonaProcessor:
    def __init__(self):
        self.sedona = sedona.db.connect()
    
    def load_geoparquet(self, parquet_path: Path | str, table_name: str):
        """Load GeoParquet into SedonaDB."""
        df = self.sedona.create_data_frame(
            self.sedona.sql(f"SELECT * FROM '{parquet_path}'")
        )
        df.to_view(table_name)
        logger.info(f"Loaded {parquet_path} as table '{table_name}'")
    
    def spatial_join(
        self,
        left_table: str,
        right_table: str,
        predicate: str = "ST_Intersects"
    ) -> any:
        """
        Perform spatial join.
        
        Predicates: ST_Intersects, ST_Contains, ST_Dwithin, etc.
        """
        query = f"""
        SELECT l.*, r.*
        FROM {left_table} l
        JOIN {right_table} r
        ON {predicate}(l.geometry, r.geometry)
        """
        return self.sedona.sql(query)
    
    def knn_join(
        self,
        point_table: str,
        polygon_table: str,
        k: int = 5
    ) -> any:
        """K-nearest neighbors spatial join (SedonaDB advantage)."""
        query = f"""
        SELECT p.*, r.ST_KNN(p.geometry, {k}) as nearest
        FROM {point_table} p
        CROSS JOIN {polygon_table} r
        """
        return self.sedona.sql(query)
    
    def to_geoparquet(self, table_name: str, output_path: Path | str):
        """Export SedonaDB table to GeoParquet."""
        df = self.sedona.sql(f"SELECT * FROM {table_name}")
        df.to_parquet(str(output_path))
        logger.info(f"Exported {table_name} to {output_path}")
```

### 2. Download Commands (`src/osm_geo_processor/cli/download.py`)

```python
import click
from pathlib import Path
from ..core.downloader import OSMDownloader

app = click.Group(help="Download OSM data")

@app.command()
@click.option("--bbox", required=True, help="Bounding box: min_lon,min_lat,max_lon,max_lat")
@click.option("--tags", help="OSM tags filter (JSON format)")
@click.option("--output", help="Output GeoParquet file path")
def region(bbox: str, tags: str, output: str):
    """Download OSM data for a region."""
    downloader = OSMDownloader()

    # Parse bbox
    bbox_coords = tuple(map(float, bbox.split(',')))

    # Parse tags if provided
    tag_dict = eval(tags) if tags else None

    # Download
    output_path = Path(output) if output else None
    result_path = downloader.download_region(
        bbox=bbox_coords,
        tags=tag_dict,
        output_path=output_path
    )
    click.echo(f"Downloaded OSM data to: {result_path}")
```

### 4. Wikidata Integration (`src/osm_geo_processor/core/wikidata.py`)

```python
from pathlib import Path
import requests
import pandas as pd
import logging

logger = logging.getLogger(__name__)

class WikidataManager:
    """Wikidata integration for OSM data enrichment."""

    def __init__(self):
        self.endpoint = "https://query.wikidata.org/sparql"

    def query_wikidata(self, query: str) -> pd.DataFrame:
        """Execute SPARQL query against Wikidata."""
        headers = {
            "User-Agent": "OSM-Geo-Processor/0.1.0",
            "Accept": "application/sparql-results+json"
        }

        response = requests.get(
            self.endpoint,
            params={"query": query, "format": "json"},
            headers=headers
        )
        response.raise_for_status()

        # Convert to DataFrame
        results = response.json()["results"]["bindings"]
        data = {
            var: [item[var]["value"] for item in results]
            for var in results[0].keys() if var in results[0]
        }
        return pd.DataFrame(data)

    def get_osm_wikidata_mapping(self, osm_id: str) -> dict:
        """Get Wikidata mapping for OSM entity."""
        query = f"""
        SELECT ?item ?itemLabel ?osmTag ?osmValue WHERE {{
          ?item wdt:P402 "{osm_id}" .
          ?item wdt:P641 ?osmTag .
          ?item wdt:P642 ?osmValue .
          SERVICE wikibase:label {{ bd:serviceParam wikibase:language "[AUTO_LANGUAGE],en". }}
        }}
        """
        df = self.query_wikidata(query)
        return df.to_dict('records') if not df.empty else {}
```

### 5. Visualization (`src/osm_geo_processor/viz/kepler_maps.py`)

```python
import geopandas as gpd
from pathlib import Path
import json

class KeplerVisualizer:
    """Kepler.GL visualization for geospatial data."""

    def __init__(self):
        self.config = {
            "version": "v1",
            "config": {
                "visState": {
                    "filters": [],
                    "layers": [],
                    "mapState": {
                        "latitude": 0,
                        "longitude": 0,
                        "zoom": 1
                    },
                    "mapStyle": {
                        "styleType": "dark"
                    }
                }
            }
        }

    def create_visualization(
        self,
        data_path: Path,
        layer_type: str = "geojson",
        label_field: str = "name"
    ) -> dict:
        """Create Kepler.GL configuration."""
        gdf = gpd.read_file(data_path)

        # Convert to GeoJSON for Kepler
        geojson = json.loads(gdf.to_json())

        # Calculate center
        bounds = gdf.total_bounds
        center_lat = (bounds[1] + bounds[3]) / 2
        center_lon = (bounds[0] + bounds[2]) / 2

        # Create layer config
        layer_config = {
            "id": "layer1",
            "type": layer_type,
            "config": {
                "dataId": "data",
                "label": label_field,
                "color": [255, 0, 0],
                "columns": {
                    "lat": "lat",
                    "lng": "lon",
                    "altitude": None
                },
                "isVisible": True,
                "visConfig": {
                    "opacity": 0.8,
                    "strokeOpacity": 0.8,
                    "thickness": 2,
                    "strokeColor": [255, 255, 255],
                    "colorRange": {
                        "name": "Global Warming",
                        "type": "sequential",
                        "category": "Uber",
                        "colors": [
                            "#5A1846",
                            "#900C3F",
                            "#C70039",
                            "#E3611C",
                            "#F1920E",
                            "#FFC300"
                        ]
                    },
                    "radius": 10
                }
            }
        }

        # Update config
        self.config["config"]["visState"]["mapState"].update({
            "latitude": center_lat,
            "longitude": center_lon,
            "zoom": 10
        })
        self.config["config"]["visState"]["layers"] = [layer_config]

        # Create data structure
        viz_data = {
            "data": [{
                "id": "data",
                "allData": geojson["features"],
                "fields": [
                    {"name": "lat", "type": "real"},
                    {"name": "lon", "type": "real"},
                    {"name": label_field, "type": "string"}
                ]
            }],
            "config": self.config
        }

        return viz_data

    def save_html(self, viz_data: dict, output_path: Path):
        """Save visualization as HTML."""
        html_template = f"""
        <!DOCTYPE html>
        <html>
        <head>
            <title>Kepler.GL Visualization</title>
            <meta charset="utf-8">
            <style>
                body, html {{ margin: 0; padding: 0; height: 100%; width: 100%; }}
                #map {{ height: 100%; width: 100%; }}
            </style>
        </head>
        <body>
            <div id="map"></div>
            <script src="https://unpkg.com/kepler.gl@latest/umd/keplergl.min.js"></script>
            <script>
                const data = {json.dumps(viz_data)};
                const keplergl = new KeplerGl({{
                    mapboxApiAccessToken: null,
                    id: 'map'
                }});
                keplergl.loadData(data.data);
                keplergl.loadMapStyle(data.config);
            </script>
        </body>
        </html>
        """

        with open(output_path, 'w') as f:
            f.write(html_template)
```

---

## Part 4: Quick Start Commands

```bash
# Setup with UV
uv init osm-geo-processor
cd osm-geo-processor

# Update pyproject.toml with the template from Part 1
# This includes all dependencies

# Install dependencies
uv sync

# Install optional dependencies for visualization
uv sync --extra viz

# Run tests
uv run pytest tests/ -v

# Format code
uv run ruff check . --fix
uv run ruff format .

# Type check
uv run pyright

# Run CLI
uv run osm-geo-cli --help
uv run osm-geo-cli version

# Use commands
uv run osm-geo-cli download region --bbox "-0.05,51.45,-0.03,51.47" --tags '{"building": ["residential"]}'
uv run osm-geo-cli process load data/osm_data.geoparquet
uv run osm-geo-cli viz map data/osm_data.geoparquet

# Launch notebook
uv run jupyter lab notebooks/
```

---

## Part 5: Performance Tips

### SedonaDB Optimization
```python
# Use SQL for complex operations (optimized query planner)
# Avoid materializing large dataframes

# Good - stays in SedonaDB
result = sedona.sql("SELECT * FROM osm WHERE ST_Area(geometry) > 1000")

# Bad - loads everything to Python
df = sedona.sql("SELECT * FROM osm").to_pandas()  # Slow!
```

### QuackOSM Caching
```python
# Caching is automatic
# Fine-tune cache location
OSMDownloader(cache_dir=Path("/fast/storage/cache"))
```

### Data Format Choice

Use **GeoParquet** for:
- Large datasets (>100MB)
- Columnar data access
- Cloud storage

Use **GeoJSON** for:
- Small datasets (<100MB)
- Web applications
- Simple feature collections

---

## Part 6: Common Workflows

### Workflow 1: Download â†’ Process â†’ Visualize
```python
from osm_geo_processor.core import OSMDownloader, SedonaProcessor
from osm_geo_processor.viz import KeplerVisualizer

# Download
downloader = OSMDownloader()
path = downloader.download_region(
    bbox=(-0.05, 51.45, -0.03, 51.47),
    tags={"building": ["residential"]}
)

# Process
processor = SedonaProcessor()
processor.load_geoparquet(path, "buildings")
result = processor.spatial_join("buildings", "roads")

# Export for visualization
processor.to_geoparquet("result", Path("data/processed/result.geoparquet"))

# Visualize
visualizer = KeplerVisualizer()
viz_data = visualizer.create_visualization(
    Path("data/processed/result.geoparquet"),
    label_field="building_type"
)
visualizer.save_html(viz_data, Path("data/processed/result.html"))
```

### Workflow 2: Enrich with Wikidata
```python
from osm_geo_processor.core import OSMDownloader, WikidataManager

# Download OSM data
downloader = OSMDownloader()
osm_data = downloader.download_region(
    bbox=(13.35, 52.50, 13.50, 52.55),  # Berlin area
    tags={"amenity": ["museum"]}
)

# Enrich with Wikidata
wiki = WikidataManager()
for feature in osm_data:
    if 'osm_id' in feature:
        wiki_info = wiki.get_osm_wikidata_mapping(feature['osm_id'])
        feature.update(wiki_info)

# Save enriched data
osm_data.to_file("data/processed/museums_with_wikidata.geojson")
```

---

## 2025 Stack Advantages

| Aspect | Old Stack (2023) | New Stack (2025) |
|--------|-----------------|-----------------|
| **Speed** | GeoPandas (baseline) | SedonaDB 5-40x faster |
| **OSM Ingestion** | osm2pgsql | QuackOSM native caching |
| **Data Formats** | Shapefiles only | GeoJSON + GeoParquet |
| **CLI** | argparse/typer | Click + Rich output |
| **Package Manager** | pip/poetry | UV (10-100x faster) |
| **Visualization** | Folium only | Kepler.GL + matplotlib |
| **Data Enrichment** | Manual lookup | Wikidata SPARQL integration |
| **Setup** | PostgreSQL required | None - single file |
| **Performance** | Basic caching | Advanced caching with QuackOSM |

---

## ðŸ—ï¸ Stack Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Your CLI/Notebook                           â”‚
â”‚              (Click + Jupyter + Rich)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚ Click â”‚   â”‚  Jupyter   â”‚   â”‚   Rich   â”‚
    â”‚ CLI   â”‚   â”‚ Notebooks  â”‚   â”‚  Logging â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚             â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Core Processing Layer   â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ â€¢ OSMDownloader(QuackOSM)  â”‚  Fetch & cache
        â”‚ â€¢ SedonaProcessor          â”‚  Spatial queries
        â”‚ â€¢ KeplerVisualizer         â”‚  Interactive maps
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚              â”‚              â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚QuackOSMâ”‚   â”‚  SedonaDB  â”‚   â”‚KeplerGL â”‚
    â”‚(caching)   â”‚ (spatial)  â”‚   â”‚(visual) â”‚
    â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚             â”‚
    â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”
    â”‚            â”‚            â”‚          â”‚
  â”Œâ”€â–¼â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â”€â–¼â”€â”€â”€â”€â”  â”Œâ”€â–¼â”€â”€â”€â”€â”€â”€â”
  â”‚OSM â”‚   â”‚GeoParquet â”‚  â”‚Local  â”‚  â”‚Jupyter â”‚
  â”‚PBF â”‚   â”‚(local)    â”‚  â”‚storageâ”‚  â”‚output  â”‚
  â””â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow Example: Download â†’ Process â†’ Visualize

```
1. CLI Command
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ osm-processor download \               â”‚
   â”‚   --bbox "-0.1,51.5,-0.05,51.55" \    â”‚
   â”‚   --tags "building:residential"        â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
2. QuackOSM Downloads
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ URL: geofabrik.de/...osm.pbf           â”‚
   â”‚ Cache: ~/.quackosm/cache/...           â”‚
   â”‚ Output: data/processed/buildings.gpq   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
3. Load into SedonaDB
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ sedona.sql("SELECT * FROM '...gpq'")   â”‚
   â”‚ sedona.sql("CREATE TABLE buildings AS  â”‚
   â”‚   SELECT * FROM '...gpq'")             â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
4. Spatial Analysis
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ sedona.sql("""                         â”‚
   â”‚   SELECT ST_Buffer(geometry, 100) as   â”‚
   â”‚   buffer FROM buildings                â”‚
   â”‚   WHERE ST_Area(geometry) > 1000       â”‚
   â”‚ """)                                   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
5. Visualize
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ KeplerVisualizer.create_map(           â”‚
   â”‚   'data/processed/result.gpq')         â”‚
   â”‚ â†’ Interactive web map in notebook      â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ’» Code Examples

### Example 1: Complete CLI Download Command

**File: `osm_geo_processor/cli/download.py`**

```python
import click
from pathlib import Path
from rich.console import Console
from rich.progress import track
from osm_geo_processor.core import OSMDownloader

console = Console()
app = click.Group(help="Download OSM data")

@app.command()
@click.option("--bbox", required=True, help="Bounding box: min_lon,min_lat,max_lon,max_lat")
@click.option("--tags", help="OSM tags filter: key:value,key:value")
@click.option("--output", type=click.Path(), default="data/processed", help="Output directory")
@click.option("--name", default="osm_data", help="Output filename (without extension)")
def region(bbox: str, tags: str, output: str, name: str):
    """Download OSM data for a region."""

    # Parse bbox
    try:
        bbox_tuple = tuple(map(float, bbox.split(",")))
        if len(bbox_tuple) != 4:
            raise ValueError
    except (ValueError, AttributeError):
        console.print("[red]Invalid bbox format. Use: min_lon,min_lat,max_lon,max_lat[/red]")
        raise click.Abort()

    # Parse tags
    tags_dict = None
    if tags:
        tags_dict = {}
        for pair in tags.split(","):
            key, value = pair.split(":")
            if key not in tags_dict:
                tags_dict[key] = []
            tags_dict[key].append(value)

    output_path = Path(output)
    output_path.mkdir(parents=True, exist_ok=True)
    final_path = output_path / f"{name}.geoparquet"

    # Download
    with console.status("[bold green]Downloading OSM data...", spinner="dots"):
        downloader = OSMDownloader()
        result_path = downloader.download_region(
            bbox=bbox_tuple,
            tags=tags_dict,
            output_path=final_path
        )

    console.print(f"[green]âœ“[/green] Downloaded to {result_path}")
    console.print(f"[cyan]Run:[/cyan] osm-geo-cli process --input {result_path}")

@app.command()
def list_cache():
    """List cached downloads."""
    from osm_geo_processor.core import OSMDownloader

    downloader = OSMDownloader()
    cache_files = list(downloader.cache_dir.glob("*.geoparquet"))

    if not cache_files:
        console.print("[yellow]No cached files found[/yellow]")
        return

    console.print("[bold]Cached OSM files:[/bold]")
    for f in cache_files:
        size_mb = f.stat().st_size / (1024 * 1024)
        console.print(f"  â€¢ {f.name:40} ({size_mb:.1f} MB)")
```

**Usage:**
```bash
# Download buildings in London
uv run osm-geo-cli download \
  --bbox "-0.1,51.45,-0.05,51.55" \
  --tags "building:residential" \
  --name "london_buildings"

# List cache
uv run osm-geo-cli download list-cache
```

---

### Example 2: Spatial Analysis with SedonaDB

**File: `osm_geo_processor/core/spatial_ops.py`**

```python
import sedona.db
import logging
from pathlib import Path
from typing import Any

logger = logging.getLogger(__name__)

class SpatialAnalyzer:
    def __init__(self):
        self.sedona = sedona.db.connect()

    def load_data(self, geoparquet_path: Path | str, table_name: str):
        """Load GeoParquet into SedonaDB."""
        df = self.sedona.sql(f"SELECT * FROM '{geoparquet_path}'")
        df.to_view(table_name)

        # Show stats
        count = self.sedona.sql(f"SELECT COUNT(*) FROM {table_name}").to_pandas()
        logger.info(f"Loaded {count.values[0][0]:,} features into '{table_name}'")

    def filter_by_area(
        self,
        table_name: str,
        min_area: float,
        max_area: float | None = None
    ) -> Any:
        """Filter geometries by area (useful for buildings)."""
        max_clause = f"AND ST_Area(geometry) <= {max_area}" if max_area else ""

        query = f"""
        SELECT * FROM {table_name}
        WHERE ST_Area(geometry) >= {min_area}
        {max_clause}
        """

        result = self.sedona.sql(query)
        result_count = result.to_pandas().shape[0]
        logger.info(f"Filtered: {result_count:,} features")
        return result

    def buffer_geometries(
        self,
        table_name: str,
        distance: float,
        output_table: str
    ):
        """Create buffers around geometries."""
        query = f"""
        SELECT
            *,
            ST_Buffer(geometry, {distance}) as buffer_geometry
        FROM {table_name}
        """

        df = self.sedona.sql(query)
        df.to_view(output_table)
        logger.info(f"Created buffers in table '{output_table}'")

    def spatial_join(
        self,
        left_table: str,
        right_table: str,
        predicate: str = "ST_Intersects",
        output_table: str | None = None
    ) -> Any:
        """
        Spatial join using various predicates.

        Predicates:
        - ST_Intersects: Geometries overlap
        - ST_Contains: Left contains right
        - ST_Within: Left is within right
        - ST_Touches: Boundaries touch
        - ST_Crosses: Geometries cross
        """
        query = f"""
        SELECT
            l.*,
            r.{[col for col in self.sedona.sql(f"SELECT * FROM {right_table} LIMIT 1").to_pandas().columns if col != 'geometry'][0]} as {right_table}_id
        FROM {left_table} l
        JOIN {right_table} r
        ON {predicate}(l.geometry, r.geometry)
        """

        result = self.sedona.sql(query)

        if output_table:
            result.to_view(output_table)
            logger.info(f"Spatial join result stored in '{output_table}'")

        return result

    def knn_join(
        self,
        points_table: str,
        polygons_table: str,
        k: int = 5,
        output_table: str | None = None
    ) -> Any:
        """
        K-nearest neighbors join.
        SedonaDB advantage: Optimized KNN implementation.
        """
        query = f"""
        SELECT
            p.*,
            r.ST_KNN(p.geometry, {k}) as k_nearest
        FROM {points_table} p
        CROSS JOIN {polygons_table} r
        """

        result = self.sedona.sql(query)

        if output_table:
            result.to_view(output_table)
            logger.info(f"KNN join result stored in '{output_table}'")

        return result

    def distance_analysis(
        self,
        table1: str,
        table2: str,
        max_distance: float,
        output_table: str | None = None
    ) -> Any:
        """Find features within distance (ST_DWithin)."""
        query = f"""
        SELECT
            t1.*,
            t2.id as {table2}_id,
            ST_Distance(t1.geometry, t2.geometry) as distance
        FROM {table1} t1
        JOIN {table2} t2
        ON ST_DWithin(t1.geometry, t2.geometry, {max_distance})
        ORDER BY distance
        """

        result = self.sedona.sql(query)

        if output_table:
            result.to_view(output_table)

        return result

    def export_result(
        self,
        table_name: str,
        output_path: Path | str,
        format: str = "geoparquet"
    ):
        """Export results to file."""
        result = self.sedona.sql(f"SELECT * FROM {table_name}")

        if format == "geoparquet":
            result.to_parquet(str(output_path))
        elif format == "geojson":
            # Convert to GeoJSON via geopandas
            gdf = result.to_pandas()
            import geopandas as gpd
            gdf = gpd.GeoDataFrame(gdf, geometry='geometry')
            gdf.to_file(output_path, driver='GeoJSON')

        logger.info(f"Exported to {output_path}")
```

**Usage in CLI:**
```python
@app.command()
@click.option("--input", required=True, type=click.Path(exists=True), help="Input GeoParquet")
@click.option("--analysis", default="filter", help="Analysis type")
def analyze(input: str, analysis: str):
    """Run spatial analysis."""
    analyzer = SpatialAnalyzer()
    analyzer.load_data(Path(input), "data")

    if analysis == "filter":
        result = analyzer.filter_by_area("data", min_area=100)
    elif analysis == "buffer":
        analyzer.buffer_geometries("data", distance=50, output_table="buffers")

    analyzer.export_result("data", Path("data/processed/result.geoparquet"))
```

---

### Example 3: Visualization in Notebook

**File: `osm_geo_processor/notebooks/03_visualization.ipynb`**

```python
# Cell 1: Imports
import geopandas as gpd
from keplergl import KeplerGL
from pathlib import Path
from osm_geo_processor.viz import KeplerVisualizer

# Cell 2: Load data
gdf = gpd.read_parquet("../data/processed/buildings.geoparquet")
print(f"Loaded {len(gdf)} features")
gdf.head()

# Cell 3: Show bounds
print(f"Bounds: {gdf.total_bounds}")
center_lat = (gdf.total_bounds[1] + gdf.total_bounds[3]) / 2
center_lon = (gdf.total_bounds[0] + gdf.total_bounds[2]) / 2
print(f"Center: ({center_lat}, {center_lon})")

# Cell 4: Create KeplerGL visualization
# Prepare data for KeplerGL
gdf_copy = gdf.copy()
# Ensure coordinates are in WGS84 for KeplerGL
if gdf_copy.crs != 'EPSG:4326':
    gdf_copy = gdf_copy.to_crs('EPSG:4326')

# Convert to GeoJSON for KeplerGL
geojson_data = gdf_copy.__geo_interface__

# KeplerGL configuration
config = {
    'version': 'v1',
    'config': {
        'visState': {
            'layers': [{
                'id': 'buildings',
                'type': 'geojson',
                'config': {
                    'dataId': 'buildings_data',
                    'label': 'Building Footprints',
                    'color': [255, 0, 0],
                    'columns': {
                        'geojson': 'geometry'
                    },
                    'isVisible': True,
                    'visConfig': {
                        'opacity': 0.8,
                        'strokeOpacity': 0.8,
                        'thickness': 2,
                        'strokeColor': [255, 255, 255],
                        'colorRange': {
                            'name': 'Global Warming',
                            'type': 'sequential',
                            'category': 'Uber',
                            'colors': [
                                '#5A1846',
                                '#900C3F',
                                '#C70039',
                                '#E3611C',
                                '#F1920E',
                                '#FFC300'
                            ]
                        }
                    }
                }
            }],
            'mapState': {
                'latitude': center_lat,
                'longitude': center_lon,
                'zoom': 13,
                'bearing': 0,
                'pitch': 0
            },
            'mapStyle': 'light'
        }
    }
}

# Create and display map
map_1 = KeplerGL(
    height=600,
    config=config
)
map_1.add_data(data=geojson_data, name='buildings_data')
map_1

# Cell 5: Save map
map_1.save_to_html("buildings_map.html")
print("Map saved to buildings_map.html")

# Cell 6: Create heatmap visualization
heatmap_config = config.copy()
heatmap_config['config']['visState']['layers'][0]['config']['visConfig']['enable3d'] = True
heatmap_config['config']['visState']['layers'][0]['type'] = 'heatmap'

map_2 = KeplerGL(
    height=600,
    config=heatmap_config
)
map_2.add_data(data=geojson_data, name='buildings_data')
map_2
```

---


---

## ðŸŽ¬ Complete Workflow: London Buildings

```bash
# 1. Download buildings in London (bounding box)
uv run osm-geo-cli download \
  --bbox "-0.1,51.45,-0.05,51.55" \
  --tags "building:*" \
  --name "london_buildings"

# Output: data/processed/london_buildings.geoparquet

# 2. Process: Filter large buildings, add buffers
uv run osm-geo-cli process \
  --input data/processed/london_buildings.geoparquet \
  --analysis filter \
  --min-area 100

# 3. Export results
uv run osm-geo-cli export \
  --input data/processed/london_buildings.geoparquet \
  --output data/processed/buildings_filtered.geoparquet

# 4. Explore in notebook
uv run jupyter lab notebooks/03_visualization.ipynb
# â†’ Run cells to visualize with KeplerGL

# 5. Full-text search or further analysis
uv run osm-geo-cli query \
  --input data/processed/london_buildings.geoparquet \
  --sql "SELECT COUNT(*) FROM data WHERE ST_Area(geometry) > 1000"
```

---

## References & Further Reading

- **SedonaDB:** https://sedona.apache.org/sedonadb/
- **QuackOSM:** https://kraina-ai.github.io/quackosm/
- **GeoParquet Spec:** https://geoparquet.org/
- **Wikidata SPARQL:** https://www.wikidata.org/wiki/Wikidata:SPARQL_query_service
- **Kepler.GL:** https://kepler.gl/
- **Click:** https://click.palletsprojects.com/
- **UV:** https://github.com/astral-sh/uv
- **Rich:** https://rich.readthedocs.io/

---

## ðŸ”§ Troubleshooting

### "SedonaDB not found" on Mac/Linux
```bash
# Install system dependencies
# macOS
brew install geos proj

# Ubuntu
sudo apt install libgeos-dev libproj-dev

uv add sedonadb
```

### "ImportError: No module named 'sedona'"
```bash
uv sync  # Reinstall all deps
```

### QuackOSM hanging or timeout
```python
# Use explicit cache control
from quackosm import QuackOSM
osm = QuackOSM(tmp_dir="/large/fast/drive")  # Faster I/O
```

### KeplerGL not rendering in Jupyter
```python
# Use in Jupyter with widget support
from keplergl import KeplerGL
KeplerGL(data=your_data, height=600)
```

---

**Last Updated:** December 2025  
**Python Version:** 3.11+  
**Status:** Production-Ready
